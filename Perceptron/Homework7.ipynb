{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " near error :  9.99945455083806e-09\n",
      " Weights :  [array([[-1.12495711, -0.29497427],\n",
      "       [-1.54450476, -0.08670286]]), array([[-1.76076534, -1.94525047],\n",
      "       [-9.53107904, -7.22517566]])]\n",
      " results:  [[0.2301722  0.00403121]]\n",
      " sig_err =   0.002740324809550839\n",
      " Weights :  [array([[-1.12496976, -0.29498186],\n",
      "       [-1.54451565, -0.08670939]]), array([[-1.7607758 , -1.94525994],\n",
      "       [-9.53118093, -7.22526792]])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "from numpy import exp\n",
    "import copy\n",
    "\n",
    "# Dataset 02\n",
    "m_input = [ [0.5, 0.3] ]\n",
    "m_output = [ [0.23, -0.07] ]\n",
    "m_w = [ [ [ 0.2, 0.5], [ -0.4, 0.6] ] , [ [ 0.1, -0.3], [ -0.5, 0.8] ]  ]\n",
    "\n",
    "def sigmoid(num_x):\n",
    "    sig = exp( num_x ) / ( 1+exp( num_x ) )\n",
    "    return sig\n",
    "\n",
    "# Deriative\n",
    "def deriv_sig(num_x):\n",
    "    dev = num_x * (1 - num_x)\n",
    "    return dev\n",
    "\n",
    "neta = 1\n",
    "def back_propagation(_input,_output, _w,_neta = neta, if_show = 0):\n",
    "\n",
    "    _layer = len(_w)\n",
    "    for i in range( len(_input) ):\n",
    "\n",
    "        _s = np.array( [ _input[i] ] )\n",
    "        _out  = np.array( _output[i])\n",
    "\n",
    "        # s_array store the parameter of each layer\n",
    "        # d_array store the devrivation      \n",
    "        s_array = [ _s]\n",
    "        d_array = []\n",
    "\n",
    "        for j in range( _layer ):\n",
    "\n",
    "            weight_j = np.array( _w[j] ) \n",
    "            # _s = np.insert( _s, 0, 1  )\n",
    "\n",
    "            _s = sigmoid( _s.dot( weight_j.T ) )\n",
    "            s_array.insert( len(s_array) , _s)\n",
    "\n",
    "\n",
    "        err_  = _s - _out\n",
    "        # err = array( [] )\n",
    "        sig_err = 1/2 * ( (_out - _s)**2 ).sum()\n",
    "\n",
    "        d0 = err_\n",
    "\n",
    "        for j in range( _layer  , 0, -1):\n",
    "            \n",
    "            m1 = d0* deriv_sig( np.array(s_array[j]) )\n",
    "            m1 = m1.reshape(2,1)\n",
    "            m2 = np.array(  s_array[j-1]  )\n",
    "            m2 = m2.reshape(1,2)\n",
    "\n",
    "            D = np.dot( m1 , m2 )\n",
    "            d_array.insert( 0, D )\n",
    "            d0 = np.sum( D, axis = 0)\n",
    "\n",
    "            _w[ j-1 ] = _w[ j-1 ] - neta * D\n",
    "\n",
    "        if if_show > 0:\n",
    "            print(\" results: \", _s)\n",
    "            print(\" sig_err =  \", sig_err)\n",
    "            print(\" Weights : \", _w  )\n",
    "\n",
    "        return _w,sig_err\n",
    "\n",
    "e1 = 1\n",
    "e2 = 0\n",
    "while np.abs(e1-e2) > 1e-8:\n",
    "    e2 = e1\n",
    "    m_w,e1 = back_propagation(m_input, m_output, m_w, 0.8)\n",
    "\n",
    "print(\" near error : \", np.abs(e1-e2))\n",
    "print(\" Weights : \", m_w  )\n",
    "m_w,e1 = back_propagation(m_input, m_output, m_w, 0.8, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
